<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Reflections on AI</title>

    <!-- SEO Meta Tags -->
    <meta name="description" content="Will there be jobs? Will this generate more inequality? Will a few large companies control everything? Will countries engage in race-to-the-bottom policymaking and forfeit our privacy and security to give their domestic companies a competitive advantage? Will the world end?">
    <meta name="keywords" content="artificial intelligence, AI, ML, machine learning">
    <meta name="author" content="Anthony Rosa">

    <!-- Open Graph Meta Tags -->
    <meta property="og:title" content="Reflections on AI">
    <meta property="og:description" content="Will there be jobs? Will this generate more inequality? Will a few large companies control everything? Will countries engage in race-to-the-bottom policymaking and forfeit our privacy and security to give their domestic companies a competitive advantage? Will the world end?">
    <meta property="og:image" content="../../images/reflections-on-ai.png">
    <meta property="og:type" content="article">

    <!-- Twitter Card Meta Tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Reflections on AI">
    <meta name="twitter:description" content="Will there be jobs? Will this generate more inequality? Will a few large companies control everything? Will countries engage in race-to-the-bottom policymaking and forfeit our privacy and security to give their domestic companies a competitive advantage? Will the world end?">
    <meta name="twitter:image" content="../../images/reflections-on-ai.png">

    <link href="../../css/bootstrap.min.css" rel="stylesheet">
    <link href="../../css/style.css" rel="stylesheet">
    <style>
      body { padding-top: 0; }
      .blogPost { padding-top: 20px !important; }
      .blogPost {
        max-width: 800px;
        margin: 0 auto;
        padding: 2rem 1rem;
      }
      .blogContent {
        font-size: 1.1rem;
        line-height: 1.8;
        color: #333;
      }
      .blogMeta {
        color: #666;
        margin: 1rem 0 2rem;
      }
      .blogImage {
        max-width: 100%;
        height: auto;
        margin: 2rem 0;
      }
    </style>
  </head>
  <body>
    <a href="../index.html" class="backArrow">←</a>
    
    <article class="blogPost">
      <div style="position: relative; z-index: 1;">
        <h1 class="xlTitle">Reflections on AI</h1>
      </div>
      
      <div class="blogImage">
        <img src="../../images/reflections-on-ai.png" alt="Reflections on AI" class="img-fluid">
      </div>

      <div class="blogMeta">
        <span class="date">September 09, 2025</span>
        <span class="author">by Anthony Rosa</span>
      </div>

      <div class="blogContent">
        <h2>Will there still be jobs?</h2>
        <p>According to an August 2025 Reuters/Ipsos poll, Americans’ second biggest concern regarding artificial intelligence (AI) is the widespread loss of jobs (Lange & Alper, 2025). Whenever a new innovation emerges and disrupts existing industries, there is a reactionary force that attempts to halt the innovation’s adoption. For example, in the early 1800s, following the advent of mechanized textile manufacturing, textile craftsmen began attacking factories, as they were unable to compete with the cheaper, less time intensive industrial outputs (Andrews, 2015). These reactionaries are known as “Luddites” today, and the name is an epithet for those who oppose progress.</p>
        <p>Ultimately, the Luddites were unsuccessful in turning the tides of history, the invisible hand of the market being too strong to conquer. While these craftsmen were displaced, and today there is a negligible amount of hand-made textiles in the US, this displacement did not result in a permanent gap in employment. Major labor upheavals are in fact the cyclical norm, and the US has already survived multiple significant changes.</p>
        <p>In 1790, 90% of the American population was employed in agriculture (National Park Service, 2022). In 2022, largely due to advances in technology enabling economies of scale, that number had dropped to 0.7% (Costa, 2023). Despite the employment sector changing for nearly all Americans, jobs are still abundant, and the latest numbers from the US Bureau of Labor Statistics reports 7.4 million jobs are unfilled (Bureau of Labor Statistics, 2025).</p>
        <p>The tendency for innovation to disrupt the labor market, and for the labor market to reorient, is an essential component of free-market economics known as creative destruction. Creative destruction may lead to short-term economic losses for specific industries, but in the aggregate it propels the economy forward by enabling the labor market to shift to higher value roles. Mechanized production may have displaced the textile craftsmen, but it also enabled the mass production of computer components, empowering the masses to work productively from anywhere in the world, and learn about any subject, at any time of the day.</p>
        <p>Just as technological manufacturing specializes in automating repeatable tasks, AI specializes in automating prediction-making (Agrawal et al., 2018, p. 2). In the short term, this puts jobs that focus on performing predictable analysis most at risk, such as alert triaging in cybersecurity, as AI can predict the correct action at a high-enough rate, with greater speed, for it to be more cost-effective than hiring a full-time employee. Since AI reduces the need for rote review of predictable tasks, judgment becomes an increasingly valuable labor skill. Machine learning, a fundamental component of AI, is error-prone and “usually impossible to get perfect accuracy” (Gupta & Mangla, 2020, p. 103). Critical alerts and decisions are too impactful to be left to error-prone algorithms, and thus the skilled and experienced manual reviewer is more valuable.</p>
        <p>Overall, jobs are still needed in the short-term, and the history of labor markets has the common lesson that there will always be jobs, but those jobs may look radically different than they do today.</p>
        
        <h2>Will this generate more inequality?</h2>
        <p>In 1774, in the era when 90% of Americans worked in agriculture, the top 1% of income earners accounted for 8.5% of the total income distribution, slaves included (Williamson & Lindert, 2016). This is approximately 2.5 times less unequal than the income distribution in the modern period. Part of the reason income inequality was less significant is due to the difficulty of multiplicative growth in low-technology farming. Farmers within the same region are subject to the same relative environmental conditions, and an acre of land is naturally limited in how many crops it can produce. This is to say that without technology, and even with it, it is extremely difficult to 100x your crop yield within the same land area.</p>
        <p>In contrast, non-physically-dependent industries are able to 100x their income streams. Software sales are not bound by geographical limitations and can be delivered to any customer anywhere in the world with an internet connection in minutes. It is no surprise that the two most common industries for billionaires to work in are finance and technology, both unconstrained by physical complications (Thomas, 2025).</p>
        <p>Broadly speaking, technology and automation compound skilled labor, exacerbating factors that produce inequality. Individuals with strong work ethic, competence, and training may have only been able to produce a geometrically greater number of crops than their less skilled neighbor, but when the more productive worker is equipped with technology, they can compound their advantage. The phenomenon for a small percentage of the population to contribute the vast majority of productive labor, and acquire the majority of income, is expressed through pareto distributions (Haley, 2022). Since AI is an automated prediction machine, we can expect the effects to generally favor those individuals, and countries, with the knowledge, skills, and economic means to access the tools, and whose work involves prediction-making.</p>
        <p>However, economic history does not demonstrate the continual enrichment of the resourceful. Wealth preservation is statistically challenging, and 90% of generational wealth is lost by the third generation (Allcot, 2023). Thus, the economic gaps produced by AI should be viewed in regards to individuals in points in time, and not necessarily in regards to society across time. Indeed, in the modern period, despite significant income inequality existing in the US, 75% of Americans will still reach the top quintile of income distribution at some point in their lives, and 50% will reach the top decile (Sowell, 2019, pp. 93, 111). It is therefore reasonable to assume that just as the advent of computing and the Internet have benefited the lower-classes, raising their average standard of living, so will the advancements that AI brings, even if the inequality gap simultaneously widens.</p>
        
        <h2>Will a few large companies control everything?</h2>
        <p>On the surface, there appears to be sufficient cause to suspect AI will be controlled by a few large companies. AI is reliant upon huge amounts of data to train accurate models, and only large organizations have the resources to mine this quantity of data. AI processing also uses specialized hardware that organizations can acquire in bulk in ways that are not cost effective for individuals. Despite these facts, free-market economies do not trend towards monopolization.</p>
        <p>There are a plethora of cases demonstrating this fact, but two stand out due to their near complete monopolization. First, in 1895, the American Sugar Refining Company owned 98% of the sugar market, but by 1927 their share plummeted to 25% (Folsom, 2010, p. 36). Second, Alcoa was the sole producer of virgin ignot aluminum in the US for decades, but in the modern period there are dozens of producers (Sowell, 2011, p. 174). Thus, even if a few large companies control the market for a period of time, we should not expect this to be permanent.</p>
        <p>Luckily, there is insufficient reason to expect this in the short-term. The US already has 43 AI companies with at least $100 million in funding, not including Google, Microsoft, or Apple (Cai, 2025). Then, there’s China with six AI companies with at least a billion yuan in funding, and Sweden, with an AI company valued at $1.5 billion (Nguyen, 2025; Chesnokova, 2025). Demonstrably, there is significant competition, within and between countries.</p>
        <p>There are two additional factors that indicate that a few large companies will not control everything: the vibrant open-source AI market and the trend of specialized models. Many large organizations release their older models as free and open-source code, and in addition to being able to self-host these models, many services, such as Venice AI and NanoGPT, offer robust free-tiers to use these models. Then, there is the emerging market trend towards tuning AI models for specific tasks. DeepSeek, a Chinese company that releases open-source models, designs their models to only activate parameters relevant to the query; whereas ChatGPT has trillions of parameters active for all queries, DeepSeek-R1 only has 37 billion (GRC, 2025, p. 7). This technique preserves approximately 90% of the model’s accuracy while reducing the model training and API costs by 95% (GRC, 2025, pp. 6-7).</p>
        <p>With the breadth of the data concerning historical trends of de-monopolization in free-market economies, the robust AI market in the US and abroad, the healthy open-source ecosystem, and the rapid reductions in cost for operating specialized models, there is little reason to fear that a few large companies will control everything.</p>
        
        <h2>Will countries engage in race-to-the-bottom policymaking and forfeit our privacy and security to give their domestic companies a competitive advantage?</h2>
        <p>This prompt presupposes several debatable tenets: the government should be intricately involved in managing the economy, the government can make ethical decisions, the government should intervene between consenting individuals, governments are broadly similar around the world, ethical decisions and economically advantageous decisions are opposed, and our privacy and security are protectable. For this discussion, only the latter three points will be disputed.</p>
        <p>The European Union epitomizes comprehensive market regulations. If a spectrum existed between ethics and the economy, compared to the US, they prioritize ethics. But, the effects of these policies elucidate that what may appear to be ethical is actually uncertain at best. According to the Financial Times, the American tech sector is around 50 times larger than Europe's, despite Europe’s better educated population, and the difference is largely due to Europe’s restrictive regulations (Romei & Smith, 2023). So, while it may sound beneficial to protect privacy and security, there is a correlative loss in economic opportunity when these principles are mandated.</p>
        <p>Whether or not privacy and security are more important than economic mobility is a personal value judgment. In free democracies, policy-mandated social values are determined by majority consensus. According to Gallup, over the past 25 years Americans have consistently ranked economic issues as their primary concern; data privacy and security have never reached the top 40 reported concerns (Gallup, 2025). Consequently, it is not clear that the ethical thing to do is to sacrifice what Americans do care about for what they do not.</p>
        <p>Additionally, Americans’ data privacy and security are essentially totally compromised already, and thus cannot be saved through new AI regulations. For example, in a single data breach in 2023, 270 million Americans’ social security numbers were leaked (Levkulich, 2024). Extending the data points beyond social security numbers, nearly 100% of Americans have sensitive data exposed on legal data broker websites or on the dark web; Experian alone advertises data on 95% of Americans and CoreLogic advertises data on “more than 99.99% of all properties” (Sherman, 2021). Framing the question as to whether the government should “forfeit our privacy and security” erroneously implies that there is meaningful data privacy and security left to forfeit.</p>
        <p>In many cases, the government is directly responsible for the lack of data privacy and security. KYC laws mandate that organizations collect and maintain personally identifiable information that is inevitably hacked. In the author’s residential state of Tennessee, the government directly sells sensitive information, such as names and current addresses, to data brokers for less than 14 cents per person (Mojica, 2020).</p>
        <p>Overall, governments that currently prioritize data privacy and security, such as Europe, are likely to continue their trajectory, while governments like the US will likely leave companies alone. This does not inherently represent a race to the bottom due to American preferences and the pre-existing dismal state of data privacy and security.</p>

        <h2>Will the world end?</h2>
        <p>There is no way to predict the future with certainty — it is possible that agentic AI systems are given control over dangerous systems, such as weapons, and they launch nuclear missiles, ending the world. This is a real threat, as current US Department of Defense policy concerning autonomous weapons systems has no requirement for a human to ever participate in the decision loop (Horowitz, 2025). We are still in the nascent stages of AI application domain discovery, and AI will be applied to new domains beyond traditional prediction applications (Agrawal et al., 2018, p. 19). Therefore, uncertainty is abundant, and much like with nuclear weapons, a lasting uncertainty is likely.</p>
        <p>Outside of these undesired consequences from AI applications, there is also the threat of losing control over AI systems. It is less likely that this manifests as sentient AI attacking humans and more likely that AI complexity increases to the point that humans cannot understand the system and effective oversight becomes impossible (Banafa, 2025). Already, AI systems are largely unintelligible to experts. The CEO of Anthropic, an AI company known for designing models that perform well with coding, remarked in April, 2025, that “we do not understand how our own AI creations work…this lack of understanding is essentially unprecedented in the history of technology” (Amodei, 2025).</p>
        <p>Herein lies the issue: if it is uncertain how AI is computing cognitive tasks in 100,000-dimension space, something no human can visualize, then it is exceedingly difficult to build proper guardrails or anticipate the consequences of deploying AI in a specific application. Coding is usually deterministic, when a programmer writes a function, barring any bugs, the code is executed the same way and the same output is produced, every time. While some machine learning programs are deterministic, such as an unsupervised clustering algorithm with a non-variable random_state, AI is not, further increasing the complexity of building a safe system.</p>
        <p>The economic principles at play are disconcerting. The cost of AI is dropping in many models, and the cheaper something is, the more it is used (Agrawal, 2018, p. 14). In many cases, the cost of AI API calls is already far cheaper than a full-time employee. Thus, the situation humanity finds itself in is wielding a tool that it does not understand, that can autonomously make decisions, and that is rapidly integrating into all industries. I am hopeful that humanity can prevent any world-wide catastrophes, as it has done with nuclear weapons, but the uniqueness of AI is that it is now in the hands of any global citizen with Internet access. Only time will reveal the consequences.</p>

        <h3>References</h3>
        <p>Agrawal, A., Gans, J., & Goldfarb, A. (2018). Prediction machines: The simple economics of artificial intelligence. Harvard Business Review Press.</p>
        <p>Allcot, D. (2023). Generational wealth “curse” is causing 90% of families to run out of money. Nasdaq.com. https://www.nasdaq.com/articles/generational-wealth-curse-is-causing-90-of-families-to-run-out-of-money-how-to-beat-the</p>
        <p>Amodei, D. (2025, April). The urgency of interpretability. Darioamodei.com. https://www.darioamodei.com/post/the-urgency-of-interpretability</p>
        <p>Andrews, E. (2015, August 7). Who were the Luddites? History. https://www.history.com/articles/who-were-the-luddites</p>
        <p>Banafa, A. (2025, May 26). Are we losing control of AI by 2027? A mixed perspective on oversight, risks, and readiness. Linkedin.com. https://www.linkedin.com/pulse/we-losing-control-ai-2027-mixed-perspective-oversight-banafa-rdekc</p>
        <p>Bureau of Labor Statistics. (2025, July 29). Job openings and labor turnover summary. BLS. https://www.bls.gov/news.release/jolts.nr0.htm</p>
        <p>Cai, K. (2025, April 10). The AI 50. Forbes. https://www.forbes.com/lists/ai50/</p>
        <p>Chesnokova, S. (2025, June 10). Sweden’s Lovable takes on Cursor and Copilot, eyes $100M at $1.5B valuation with AI that lets anyone build apps. Tech Funding News. https://techfundingnews.com/swedens-lovable-takes-on-cursor-and-copilot-eyes-100m-at-1-5b-valuation-with-ai-that-lets-anyone-build-apps/</p>
        <p>Costa, D. (2023, October 3). How many farmworkers are employed in the United States? Economic Policy Institute. https://www.epi.org/blog/how-many-farmworkers-are-employed-in-the-united-states/</p>
        <p>Folsom, B. W. (2010). The myth of the robber barons (6th ed.). Young America’s Foundation.</p>
        <p>Gallup. (2025, August 28). Most Important Problem. Gallup. https://news.gallup.com/poll/1675/most-important-problem.aspx</p>
        <p>GRC. (2025). Jailbreaking AI. Gibson Research Corporation. https://www.grc.com/sn/sn-1011-notes.pdf</p>
        <p>Gupta, N., & Mangla, R. (2020). Artificial intelligence basics: A self-teaching introduction. Mercury Learning and Information.</p>
        <p>Haley, C. (2022, March 15). Explaining the 80-20 rule with the Pareto Distribution. Dlab.berkeley.edu. https://dlab.berkeley.edu/news/explaining-80-20-rule-pareto-distribution</p>
        <p>Horowitz, M. (2025, May 22). Autonomous weapon systems: No human-in-the-loop required, and other myths dispelled. War on the Rocks. https://warontherocks.com/2025/05/autonomous-weapon-systems-no-human-in-the-loop-required-and-other-myths-dispelled/</p>
        <p>Lange, J., & Alper, A. (2025, August 20). Americans fear AI permanently displacing workers, Reuters/Ipsos poll finds. Reuters. https://www.reuters.com/world/us/americans-fear-ai-permanently-displacing-workers-reutersipsos-poll-finds-2025-08-19/</p>
        <p>Levkulich, J. (2024, September 8). Huge data breach involving social security numbers could impact millions of Americans. News 5 Cleveland WEWS. https://www.news5cleveland.com/news/local-news/huge-data-breach-involving-social-security-numbers-could-impact-millions-of-americans</p>
        <p>Mojica, A. (2020, February 17). Personal information of 7.2 million Tennessee drivers sold to companies by state agency. WZTV. https://fox17.com/news/local/personal-information-of-72-million-tennessee-drivers-sold-to-companies-by-state-agency</p>
        <p>National Park Service. (2022, April 6). “The dust of many a hard-fought field” - Place attachment and agriculture at Minute Man. US National Park Service. https://www.nps.gov/articles/000/-the-dust-of-many-a-hard-fought-field-place-attachment-and-agriculture-at-minute-man.htm</p>
        <p>Nguyen, B. (2025, March 10). Meet the “six tigers” that dominate China’s AI industry. Quartz. https://qz.com/china-six-tigers-ai-startup-zhipu-moonshot-minimax-01ai-1851768509</p>
        <p>Romei, V., & Smith, C. (2023, October 19). How is the US economy managing to power ahead of Europe? Financial Times. https://www.ft.com/content/e0177eb7-8d17-48aa-a6ad-fccd0655f557</p>
        <p>Sherman, J. (2021). Data brokers and sensitive data on U.S. individuals threats to American civil rights, national security, and democracy. Duke Sanford Cyber Policy Program. https://techpolicy.sanford.duke.edu/wp-content/uploads/2021/08/Data-Brokers-and-Sensitive-Data-on-US-Individuals-Sherman-2021.pdf</p>
        <p>Sowell, T. (2011). Basic economics (4th ed.). Basic Books.</p>
        <p>Sowell, T. (2019). Discrimination and disparities. Basic Books.</p>
        <p>Thomas, G. (2025, April 3). The 10 most popular industries for billionaires 2025. Forbes. https://www.forbes.com/sites/gracethomas/2025/04/03/how-the-worlds-billionaires-got-so-rich-2025/</p>
        <p>Williamson, J. G., & Lindert, P. (2016, June 16). Unequal gains: American growth and inequality since 1700. CEPR. https://cepr.org/voxeu/columns/unequal-gains-american-growth-and-inequality-1700</p>
      </div>
    </article>

    <!-- Footer -->
    <footer>
      <div class="footerCol">
        <div class="container">
          <ul class="socialCol">
            <li><a href="mailto:anthonyrosa@crypticrisk.com"><img src="../../images/email.png"></a></li>
            <li><a href="https://github.com/tacolopo"><img src="../../images/github.png"></a></li>
            <li><a href="https://crypticrisk.com"><img src="../../images/crypticrisk.png"></a></li>
          </ul>
        </div>
      </div>
    </footer>

    <!-- Scripts -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
    <script src="../../js/bootstrap.bundle.min.js"></script>
  </body>
</html> 
